<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Yura Choi</title>
  <meta name="author" content="Yura Choi">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Yura Choi (최유라)</name>
                  </p>
                  <p style="text-align:justify">
                    I am a first-year Ph.D. student in the Department of Computing at Imperial College London, advised by Dr. Jiankang Deng and Prof. Stefanos Zafeiriou.
                    My Ph.D. study is supported by the Department of Computing Scholarship.
                  </p>
                  <p style="text-align:justify">
                    My primary research interests lie in building user-friendly intelligent assistants equipped with spatio-temporal aware video understanding capabilities, leveraging Multimodal Large Language Models (MLLMs).
                  </p>
                  <p style="text-align:justify;">
                    Previously, I received my M.S. degree in Artificial Intelligence from Yonsei University and my B.S. degree in Electrical Engineering and Computer Science from Gwangju Institute of Science and Technology (GIST), both under the supervision of Prof. Jonghyun Choi.
                    During my master's, I focused on aligning video modalities for LLMs using preference optimization techniques such as RLAIF and DPO, as well as improving text-to-video retrieval capabilities.
                  </p>
                  <p style="text-align:center">
                    <a href="personal/0924_CV_yurachoi.pdf" target="_new">CV</a> &nbsp/&nbsp
                    <a href="mailto:yc825@ic.ac.uk">Email</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=hX1KQvMAAAAJ" target="_new">Google Scholar</a> &nbsp/&nbsp
                    <a href="https://github.com/Yuuraa/" target="_new">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/yura_circle.jpg"><img style="width:70%;max-width:70%" alt="profile photo" src="personal/windy.jpeg" class="hoverZoomLink"></a>
                  <br><br>
                  <a href="images/yura_circle.jpg"><img style="width:70%;max-width:70%" alt="profile photo" src="personal/londonbridge.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <hr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Work Experience</heading>
                    </td>
                </tr>
            </tbody>
          </table>
        
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:15%;vertical-align:middle">
                  <img src='work_experiences/HuaweiUKRD/logo.png' style="border-style: none; width:100%; max-width:100%;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>
                    <a href="https://huaweiuk.teamtailor.com">Huawei Noah's Ark Lab, UK</a>
                  </papertitle>
                  <br>
                  Research Intern at <a href="https://huaweiuk.teamtailor.com">Multimodality Team</a> (Jan. 2025 ~ Jan. 2026)
                  <br>
                  Mentor: <a href="https://therevanchist.github.io/">Ismail Elezi</a>, <a href="https://roymiles.github.io/">Roy Miles</a>, <a href="https://jiankangdeng.github.io/">Jiankang Deng</a>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Publications</heading>
                    </td>
                </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div style="
                    width:100%;
                    aspect-ratio: 16 / 9;
                    background:#d9d9d9;
                    border:1px solid #bdbdbd;
                    border-radius:8px;
                    display:flex;
                    align-items:center;
                    justify-content:center;
                    color:#666;
                    font-size:14px;
                  ">
                    Teaser coming soon
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>
                        A Paper About Egocentric Gesture-Based Assistants
                    </papertitle>
                  <br>
                  <strong><u>Yura Choi</u></strong>*,
                  Roy Miles,
                  Rolandos Alexandros Potamias,
                  Ismail Elezi,
                  Jiankang Deng,
                  Stefanos Zafeiriou
                  <br>
                  Under review
                  <br>
                  [<a href="javascript:void(0)">paper (coming soon)</a>]
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src='papers/ahn2025vector/teaser.png' style="border-style: none; width:100%;max-width:100%">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>
                        What Happens When: Learning Temporal Orders of Events in Videos
                    </papertitle>
                  <br>
                  Daechul Ahn*,
                  <strong><u>Yura Choi</u></strong>*,
                  Hyeonbeom Choi*,
                  Seongwon Cho,
                  San Kim,
                  Jonghyun Choi
                  <br>
                  WACV 2026 (To appear)
                  <br>
                  [<a href="javascript:void(0)">paper (coming soon)</a>]
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src='papers/choi2025vcmr/teaser.png' style="border-style: none; width:100%;max-width:100%">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>
                        Moment-Aware Video Retrieval for Video Corpus Moment Retrieval
                    </papertitle>
                  <br>
                  <strong><u>Yura Choi</u></strong>*,
                  Daechul Ahn*,
                  San Kim,
                  Jonghyun Choi
                  <br>
                  IEEE ACCESS 2025
                  <br>
                  [<a href="https://ieeexplore.ieee.org/abstract/document/10902083" target="_new">paper</a>]
                  [<a href="https://dcahn12.github.io/papers/choi2025ma-vr/access2025_ma-vr.bib" target="_new">bibtex</a>]
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src='papers/ahn2024srt/teaser.png' style="border-style: none; width:100%;max-width:100%">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>
                        Iterative Self-Retrospective Judgement for Multimodal Large Language Models for Videos
                    </papertitle>
                  <br>
                  Daechul Ahn*,
                  <strong><u>Yura Choi</u></strong>*,
                  San Kim,
                  Youngjae Yu,
                  Dongyeop Kang,
                  Jonghyun Choi
                  <br>
                  AAAI 2025
                  <br>
                  [<a href="https://arxiv.org/abs/2406.11280" target="_new">paper</a>]
                  [<a href="https://dcahn12.github.io/papers/ahn2025isr-dpo/aaai2025_isr-dpo.bib" target="_new">bibtex</a>]
                  [<a href="https://github.com/snumprlab/isr-dpo" target="_new">code</a>]
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src='papers/ahn2024vlmrlaif/rlaif_performance_radar.jpeg' style="border-style: none; width:100%;max-width:100%">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                    <papertitle>
                        Tuning Large Multimodal Models for Videos using Reinforcement Learning from AI Feedback
                    </papertitle>
                  <br>
                  Daechul Ahn,
                  <strong><u>Yura Choi</u></strong>,
                  Youngjae Yu,
                  Dongyeop Kang,
                  Jonghyun Choi
                  <br>
                  ACL 2024 (<strong>Oral Presentation</strong>)
                  <br>
                  [<a href="https://arxiv.org/abs/2402.03746" target="_new">paper</a>]
                  [<a href="./projects/VLM_RLAIF" target="_self">project page</a>]
                  [<a href="papers/ahn2024vlmrlaif/ahn2024tuning.bib" target="_new">bibtex</a>]
                  [<a href="https://github.com/yonseivnl/vlm-rlaif" target="_new">code</a>]
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Scholarships</heading>
                    </td>
                </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px;">
                    <ul>
                        <li>Doctoral Scholarship Award, DoC Imperial College London, London, United Kingdom
                        <ul>
                            <li>Full tuition and a living stipend for the duration of the PhD program</li>
                            <li>May 2025 - May 2029</li>
                        </ul>
                        </li>
                    </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    This template is from <a href="https://jonbarron.info/" target="new">Jon Barron</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
    </tbody>
  </table>

  <script type="text/javascript">
  var sc_project=12971284;
  var sc_invisible=1;
  var sc_security="2387cd11";
  </script>
  <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
  <noscript>
    <div class="statcounter">
      <a title="Web Analytics" href="https://statcounter.com/" target="_blank">
        <img class="statcounter" src="https://c.statcounter.com/12971284/0/2387cd11/1/" alt="Web Analytics" referrerPolicy="no-referrer-when-downgrade">
      </a>
    </div>
  </noscript>
  </body>
</html>