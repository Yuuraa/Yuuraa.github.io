---
title: "[ TIL ] 0807 - Task Oriented Dialogue System 소개 & NeuralWOZ" 
date: 2021-08-07 23:57:30 -0400
categories: til 졸논 DST NeuralWOZ nlp\ 대충\ 스터디
---


## Task-Oriented Dialog System (TOD system), 해결 과제 소개

### Task-oriented dialog system(TOD)이란?
- 
    - Task-oriented dialog system(TOD system)이란, 특정 **목적을 지닌 사용자의 요구 사항을 파악**하고, 이를 수행하기 위한 대화 시스템이다. 예를 들어 레스토랑 예약, 날씨 정보 문답 등을 해주는 챗봇 들이 TOD system이다.
    - vs. Open-domain dialog systems (Social chit-chat) → 사용자의 참여를 최대화 하는 것이 목적으로 하는 dialog system.  챗봇 '이루다' 처럼, 일상 대화를 하는 챗봇을 포함한다.
    - 문제 정의 & 용어 정리
        1. User Goal - 미리 정의된 knowledge base에서 특정 정보를 찾거나, 추가적 정보 제공으로 (제약 사항) 새로운 정보를 찾고자 한다고 가정한다 ex) "OO 레스토랑 예약해줘" → 특정 OO 레스토랑 찾음, "분당에 있는 레스토랑 예약하려고 하는데" → 위치가 분당에 있는 레스토랑 정보를 찾음
        2. Knowledge base - 시나리오에서 제공되는 정보들을 담은 데이터베이스. ex) 레스토랑에 대한 정보들 - ex) {"브라운돈까스": {'위치': '분당 서현동', '가격대': '적절', '예약 가능 인원': '30명'}, "미소야": ...,}
        3. Task schema - 사용자가 원하는 정보를 찾거나 시나리오에 있는 정보를 주도록 정의된 정보. 태스크와 연관되어 있다
        - Domain - 숙소, 레스토랑 등 대화에서 다루는 주제의 종류
        - Slot - 숙소-이름, 숙소-종류, 숙소-가격대 등의 정보들
        - Value - Slot에 대한 값. 숙소-이름 slot의 value로 "OO호텔" 등이 있다

  <img width="80%" alt="image" src="https://user-images.githubusercontent.com/48202492/128606862-9e186141-f8ca-44a6-978b-da8557098bb7.png">


### TOD 분류 - single turn/multi turn, single domain/multi domain
- 
    <img width="80%" style="align:center;" alt="image" src="https://user-images.githubusercontent.com/48202492/128606882-aea771ec-ae84-42cb-adaa-f1f8899f7d08.png">
    
    자료 출처: 고려대학교 DSBA 이유경님 발표 자료 [https://www.youtube.com/watch?v=nuclwoebdEM&t=113s](https://www.youtube.com/watch?v=nuclwoebdEM&t=113s)

    - TOD를 Single turn conversation과 **multi turn conversation**으로 다시 나눌 수 있는데, 사용자가 원하는 답을 시스템이 도출하기 까지 한 번의 하는 방식과, 여러 번의 대화를 하는 방식이 있다
        - Multi turn의 경우, 이전 대화에서의 정보를 기억해야 하는 등 비교적 어렵지만, 활용 가능한 정보가 많아 수준 높은 답을 생성할 가능성이 있다
    - Dialogue 내에 도메인의 갯수로 데이터 또한 분리할 수 있는데, single domain의 경우 "호텔 예약"등 하나의 도메인과 관련된 대화만을 포함하고, **multi domain**의 경우 "호텔 예약"이 "레스토랑 예약" 까지  여러 개의 도메인을 포함할 수 있는 데이터에 대해 학습한다

### 문제 접근 방법
- 
    - TOD system을 학습하는 데에는 pipeline 방식과 end-to-end 방식, 두 가지의 접근 방법이 있다
        - **Pipeline 방식**은 dialog system을 크게 4개의 모듈로 나누는데,
            - Natural Language Understanding (NLU) - 사용자의 발화를 분석하여 정형화된 값으로 만드는 모듈
            - Dialog State Tracking (DST) - 현재까지 대화에서 나온 정보를 파악하는 모듈
            - Dialog Policy (DP) - 정보를 통해 특정 행동을 하도록 학습하는 모듈
            - Natural Language Generation (NLG) - 시스템의 응답을 만드는 모듈이 있다

            <img width="80%" style="align:center;" alt="image" src="https://user-images.githubusercontent.com/48202492/128606717-7da17f1f-adb3-421e-983d-9564db27aa64.png">
            <img width="80%" style="align:center;" alt="image" src="https://user-images.githubusercontent.com/48202492/128606733-1301224a-f2a5-4f1d-ab06-332bfdc7a796.png">
            자료 출처: 고려대학교 DSBA 이유경님 발표 자료 [https://www.youtube.com/watch?v=nuclwoebdEM&t=113s](https://www.youtube.com/watch?v=nuclwoebdEM&t=113s)

            - word-level DST: NLU + DST
            - word-level policy: Policy + NLG 이런 식으로 몇몇 접근법에서는 두 가지 모듈이 병합되기도 한다
        - **End-to-end 방식**은 사용자 자연어를 입력으로 받고 시스템 응답을 출력으로 받는 하나의 모델을 구현한다

### 참고 자료
- 
    - Recent Advances and Challenges in Task-oriented Dialog Systems -  [https://arxiv.org/pdf/2003.07490.pdf](https://arxiv.org/pdf/2003.07490.pdf)
    - [https://www.youtube.com/watch?v=nuclwoebdEM&t=113s](https://www.youtube.com/watch?v=nuclwoebdEM&t=113s)
    - [https://hijigoo.github.io/nlp/2020/05/16/dialog-system-01/](https://hijigoo.github.io/nlp/2020/05/16/dialog-system-01/)

## TOD 데이터셋의 종류 & 한계

### 데이터셋의 종류
- 
    - WOZ

        두 명의 사람이 역할을 맡아 **롤플레잉 하는 식으로 데이터를 수집**한다. 한 명은 사용자, 한 명은 시스템 역할을 맡고, 사용자는 주어진 goal instruction (ex: 영국식 음식을 파는 레스토랑을 예약하고 싶다 등)을 바탕으로, 시스템은 knowledge base (KB) 로부터의 쿼리 결과를 바탕으로 (ex: 영국식 레스토랑 검색 결과 나온 목록) 대화한다.

        레스토랑 예약 도메인에 대해 데이터를 수집했다

    - **MultiWOZ**

        여러 개의 도메인에 대해 WOZ와 같은 방식으로 데이터를 수집했다

    - DSTC, DSTC2

        각각 버스 시간표, 레스토랑 예약에 대한 single domain. 한 대화문 당 14~15개의 턴으로 이루어져 있고 각 턴 마다 8개 정도의 토큰을 담은 문장 사용. 대화 상태와 사용자/시스템의 대화문을 포함한다

    - 이외에도 bAbI, KVReT, Frames, SimD, AirD, MDC, CoSQL, Taskmaster, SGD, CamRest 등의 데이터셋 존재

### TOD 데이터셋의 취약점
- 
    - **확장성(Scalability) 문제**

        WOZ 방식으로 수집하는 것이 많으나, 사람 두 명이서 한 명은 사용자, 한 명은 시스템 역할을 맡으므로 **비용이** 비싸고, 수작업으로 대화 상태를 라벨링 하니 많은 양의 annotation **error**가 발생한다. 또한, 데이터 **분포를** 제어하기 쉽지 않다. 따라서, 새로운 도메인, 새로운 정보에 대해 데이터와 모델을 확장하기 어렵다.

    - **강건함(Robustness) 문제**
        1. **인공적인 대화체**로 이루어진 데이터로 인한 현실과의 괴리 → 실제 서비스에서 수집된 dialogue와 재조합하면, 또는 실제로 발생할 수 있는 대화 패턴으로 살짝 변형된 데이터를 사용해도 사전 학습된 모델들 (end-to-end 모델에서 실험했을 때)의 성능이 대폭 하락함

            > Effects of Naturalistic Variation in Goal-Oriented Dialog (2020, Ganhotra et al.)
            <img width="801" alt="image" src="https://user-images.githubusercontent.com/48202492/128606771-84628831-25ce-4382-839e-fcc27f78a696.png">


        2. **Counterfactual** goal: 데이터셋에서 일부 goal들을 잘 반영하지 못함. 

            > COCO: Controllable Counterfactuals for Evaluating Dialogue State Trackers (2020, Li et al.)

            MultiWOZ 데이터셋을 분석했을 때 두 가지 큰 문제를 발견함

            1. 대부분 학습 데이터에서 많이 등장한 slot 종류들이 테스트셋에서 등장함. Unseen type이 없는 문제
            2. Multi domain이나, 함께 등장하는 도메인들의 분포에 편향이 있음 → "예약 인원수 + 가격대" 등 실생활에서 같이 등장하기 쉬우나 반영되지 못한 분포도 있음
        - 사용자 발화 생성 + counterfactual goal generator를 사용하고, counterfactual한 대화문을 생성해 이에 대해 기존 DST 모델을 실험함. Slot의 값만을 학습에서 보지 못한 데이터로 교체하는 Coco change의 경우에서도 모델들의 성능이 크게 떨어짐. 또한, domain들의 co-occurrence 비율에 따라 다른 샘플링을 한 경우 성능이 거의 절반으로 하락해, 강건하지 않은 데이터임을 밝힘
            <img width="1043" alt="image" src="https://user-images.githubusercontent.com/48202492/128606785-b9f30543-f2e1-43f9-a89a-a18f349293d7.png">

        - COCO에서 제시된 counterfactual-goal 데이터 생성 방법은 이후 MultiWOZ 2.1 데이터셋을 보완하는 데에 사용됨

## 딥러닝 모델로 TOD 데이터셋 만들기 - NeuralWOZ (ACL 2021)

ACL 2021 / NAVER AI Lab / Task-oriented dialogue / 데이터 증강

### 논문 간단 요약
- 
    - **Multi domain dialogue 데이터셋을 생성하는 모델 기반 프레임워크**
    - Dialogue State Tracking 태스크의 모델 - TRADE, SUMBT 모델을 학습시켰을 때 zero-shot 문제와 full data augmentation 모두 SOTA 성능으로 이어졌다
    - 다른 증강 방식인 ATDM, VHDA와 비교했을 때에도 가장 높은 모델 성능 향상을 이뤄냈다

### 데이터를 통한 성능 향상 지표
- 

    DST 태스크에서의 성능 향상 지표로는 각 턴 별로 모든 slot의 값이 알맞게 예측했는지를 측정하는 joint goal accuracy(JGA)와 slot별 정확도를 구한 slot accuracy(SA)를 사용했다

### 데이터 생성 방식
- 
    모델은 Collector와 Labeler로 이루어졌고, 크게 goal instruction ←  (goal template에서 새로 생성됨), api call results (knowledge base)을 사용해 대화문을 생성하고, 라벨러는 이 대화문과  state candidate을 받아 각 slot-value 쌍 값을 선택한다

    - 기존 데이터에서 goal instruction의 slot value들을 slot으로 대치한 뒤, 이를 다른 도메인의 slot으로 변경하고, 그에 맞는 API 호출 결과로 값을 채워 넣는 방식으로 새로운 Goal Instruction과 state candiadate (상태 후보)를 생성했다
    - Collector는 사전학습된 BART 모델을 기반으로 새로운 Goal Instruction과 API 호출 결과로부터 대화문을 생성한다
    - Labeler는 사전 학습된 RoBERTa 모델을 바탕으로, 생성된 대화문과 State candidate으로부터 만들어진 question을 받아 각 대화의 대화 상태를 라벨링한다
    <img width="500" alt="image" src="https://user-images.githubusercontent.com/48202492/128606809-ec0786c9-72f2-4943-b948-9e0531a447e1.png">



### DST 모델 학습 실험 결과 - Zero-shot transfer learning/ Full Data Augmentation
- 
    - 타겟 도메인을 제외한 나머지 도메인에서 증강한 데이터를 사용해 학습한 Zero-shot transfer learning에서도 나머지 도메인에서 NeuralWOZ 프레임워크로 데이터 증강 후 학습시켰을 때 다른 방식으로 증강한 데이터를 사용했을 때에 비해 성능 향상을 보였다.
        - Zero-shot에서는 타겟 도메인을 제외한 나머지 도메인에서 증강한 데이터를 사용해 학습하고, 보지 못한 타겟 도메인에서의 성능을 본다
        - 데이터 증강을 하지 않았을 때의 결과와 ATDM 데이터 합성 방식을 사용해 데이터를 증강하고 모델을 학습시켰을 때의 결과와 비교하였을 때, 가장 높은 성능 향상을 보였다
     <img width="1069" alt="image" src="https://user-images.githubusercontent.com/48202492/128606820-b3206eb2-5c2c-4eee-9e35-733e8c175653.png">

- 또한, 전체 도메인에 대해서 Data augmentation을 진행하고 학습시켰을 때에도 각 도메인 별로 DST 모델들의 성능 향상 효과가 있음을 보여 생성한 데이터셋의 유용성을 증명했다
    - ATDM, 데이터 합성 방식을 사용해 데이터를 증강하고 모델을 학습시켰을 때와 결과를 비교하였으며, VHDA의 경우 single domain에서의 증강 방식이므로 단일 도메인에 대해 비교를 진행하였다. 모두 다른 증강 방식에 비해 성능이 더 증가함을 확인했다
     <img width="1052" alt="image" src="https://user-images.githubusercontent.com/48202492/128606835-4ef7c643-c899-469e-acb4-658ba3f23247.png">

     


- 추가 실험: End-to-End Task에서의 실험
    - 기존 End-to-End 모델을 동일하게 학습시키진 않았지만, GPT2 모델에 데이터셋을 학습시켰을 때, 생성된 응답 평가 지표인 BLEU, 정보를 잘 담았는지를 평가하는 Inform과 Success 등의 평가 지표를 종합했을 때 준수한 성능을 보임
        <img width="1051" alt="image" src="https://user-images.githubusercontent.com/48202492/128606841-84a419a4-35ce-49bb-b6e3-eba4cbc2441e.png">
